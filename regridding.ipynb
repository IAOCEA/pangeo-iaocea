{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# regridding\n",
    "\n",
    "The regridding usually happens on the fly for satellite imagery and in-situ data, but to demonstrate how this works this notebook does this separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import distributed\n",
    "\n",
    "client = distributed.Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import warnings\n",
    "\n",
    "import geopandas as gpd\n",
    "import pystac\n",
    "import shapely\n",
    "import stac_geoparquet\n",
    "import xarray as xr\n",
    "import xdggs\n",
    "from rich.progress import track\n",
    "\n",
    "from pangeo_iaocea.regridding import aggregation_regridding, categorize_points\n",
    "from pangeo_iaocea.subsetting import subset_dataset\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    category=UserWarning, message=\"Consolidated metadata\", action=\"ignore\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_root = pathlib.Path(\"data\")\n",
    "stac_root = cache_root / \"stac\"\n",
    "healpix_root = cache_root / \"healpix\"\n",
    "raw_root = cache_root / \"raw\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "area of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox = shapely.box(-8, 46, 1, 51)\n",
    "datetime = [\"2022-05-10T00:00:00\", \"2022-05-12T00:00:00\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## regrid SST imagery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "First, we need to define the target resolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_info = xdggs.HealpixInfo(level=11, indexing_scheme=\"nested\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "To regrid, we can first read the stored items back into memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_items = gpd.read_parquet(stac_root / \"avhrr-sst-metop_b.parquet\").pipe(\n",
    "    stac_geoparquet.to_item_collection\n",
    ")\n",
    "image_items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "and then apply the regridding by looping over the items. For each item, we:\n",
    "- use `xpystac` to load the given asset into an `xarray` object\n",
    "- apply aggregation regridding (bin the original data into healpix cells and compute bin means)\n",
    "- write the result with uniform chunk sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "regridded_root = healpix_root / \"avhrr-sst-metop_b\"\n",
    "regridded_root.mkdir(parents=True, exist_ok=True)\n",
    "subset_root = raw_root / \"avhrr-sst-metop_b\"\n",
    "subset_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for item in track(image_items):\n",
    "    ds = xr.open_dataset(\n",
    "        item.assets[\"data\"], engine=\"stac\", chunks={}, decode_timedelta=True\n",
    "    )\n",
    "\n",
    "    subset = ds.pipe(subset_dataset, bbox)\n",
    "    if {k: v for k, v in subset.sizes.items() if v == 0}:\n",
    "        print(f\"skipping f{item.id} (item bbox doesn't match the actual geometry)\")\n",
    "        continue\n",
    "\n",
    "    path = subset_root.joinpath(item.id).with_suffix(\".zarr\")\n",
    "    subset.to_zarr(path, mode=\"w\")\n",
    "\n",
    "    regridded = aggregation_regridding(grid_info, subset).chunk({\"cells\": 100000})\n",
    "    path = regridded_root.joinpath(item.id).with_suffix(\".zarr\")\n",
    "    regridded.to_zarr(path, mode=\"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "We can then open one of these and visualize the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = xr.open_dataset(\n",
    "    regridded_root.joinpath(image_items[1].id).with_suffix(\".zarr\"),\n",
    "    engine=\"zarr\",\n",
    "    decode_timedelta=True,\n",
    "    chunks={},\n",
    ").dggs.decode()\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "image[\"sea_surface_temperature\"].compute().dggs.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## transform in-situ data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "For the in-situ data, the procedure is the same:\n",
    "- open the datasets\n",
    "- define the grid\n",
    "- bin the coordinates\n",
    "\n",
    "However, there is no regridding involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "insitu_items = [\n",
    "    pystac.Item.from_dict(item)\n",
    "    for item in stac_geoparquet.json_reader.read_json(\n",
    "        stac_root / \"insitu_global_phybgcwav_discrete_mynrt_013_030.jsonl\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "We'll use a higher-resolution grid to accomodate the point / trajectory data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_info = xdggs.HealpixInfo(level=13, indexing_scheme=\"nested\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "With that, we can derive cell ids from the geographic coordinates provided by the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_attrs(ds):\n",
    "    def fix_value(val):\n",
    "        if not isinstance(val, str):\n",
    "            return val\n",
    "\n",
    "        return val.encode(\"utf-8\", \"surrogateescape\").decode(\"utf-8\")\n",
    "\n",
    "    def fix_values(attrs):\n",
    "        return {k: fix_value(v) for k, v in attrs.items()}\n",
    "\n",
    "    # work around the generally broken string encoding in the insitu tac\n",
    "    fixed = ds.copy()\n",
    "\n",
    "    for var in fixed.variables.values():\n",
    "        var.attrs = fix_values(var.attrs)\n",
    "    fixed.attrs = fix_values(fixed.attrs)\n",
    "\n",
    "    return fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "regridded_root = healpix_root / \"insitu_global_phybgcwav_discrete_mynrt_013_030\"\n",
    "for item in track(insitu_items):\n",
    "    ds = (\n",
    "        xr.open_dataset(item.assets[\"public\"], engine=\"stac\", chunks={})\n",
    "        .pipe(fix_attrs)\n",
    "        .compute()\n",
    "        .drop_vars([\"PRECISE_LONGITUDE\", \"PRECISE_LATITUDE\"], errors=\"ignore\")\n",
    "    )\n",
    "    subset = ds.pipe(subset_dataset, bbox)\n",
    "    if {k: v for k, v in subset.sizes.items() if v == 0}:\n",
    "        print(f\"skipping {item.id}\")\n",
    "        continue\n",
    "\n",
    "    path = regridded_root.joinpath(item.id).with_suffix(\".nc\")\n",
    "    subset.assign_coords(\n",
    "        {\"cell_ids\": categorize_points(grid_info, ds[\"LONGITUDE\"], ds[\"LATITUDE\"])}\n",
    "    ).to_netcdf(path, mode=\"w\", engine=\"h5netcdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "The datasets are small enough to stay in memory, so we can immediately visualize the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(\n",
    "    regridded_root.joinpath(insitu_items[2].id).with_suffix(\".nc\"),\n",
    "    engine=\"h5netcdf\",\n",
    "    chunks={},\n",
    ")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.dggs.decode().compute().get(\"TEMP\").dggs.explore()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
