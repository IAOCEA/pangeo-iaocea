{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# searching a STAC catalog for different kinds of data\n",
    "\n",
    "This notebook aims to demonstrate how to search different kinds of data in a STAC catalog, using the same search criteria.\n",
    "\n",
    "For this, we need:\n",
    "- `shapely` to define the search geometry\n",
    "- `pystac-client` to query the STAC API\n",
    "- `stac-geoparquet` to store the queried items as `geoparquet` files\n",
    "- `geopandas` to work around an issue with `stac-geoparquet`\n",
    "- `pyarrow` to read the `geoparquet` files\n",
    "- `lonboard` to visualize the geometries\n",
    "- `stac-insitu` to filter trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pathlib\n",
    "\n",
    "import geopandas as gpd\n",
    "import lonboard\n",
    "import numpy as np\n",
    "import pyarrow.parquet as pq\n",
    "import pystac\n",
    "import pystac_client\n",
    "import shapely\n",
    "import stac_geoparquet\n",
    "from matplotlib import colormaps\n",
    "from stac_insitu.filter import filter_trajectories\n",
    "\n",
    "cache_root = pathlib.Path.home() / \"work/data/stac/cache\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "some functions for easy I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_to_ndjson(collection, path):\n",
    "    with open(path, \"w\") as f:\n",
    "        for item in collection:\n",
    "            json.dump(item.to_dict(), f, separators=(\",\", \":\"))\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "\n",
    "def read_ndjson(path):\n",
    "    \"\"\"read geometries and IDs from a ndjson file\"\"\"\n",
    "    with open(path) as f:\n",
    "        items = [pystac.Item.from_dict(json.loads(line)) for line in f]\n",
    "\n",
    "    geometries = [shapely.from_geojson(json.dumps(item.geometry)) for item in items]\n",
    "    collection_ids = [item.collection_id for item in items]\n",
    "    item_ids = [item.id for item in items]\n",
    "    return gpd.GeoDataFrame(\n",
    "        {\"collection\": collection_ids, \"id\": item_ids},\n",
    "        geometry=geometries,\n",
    "        crs=\"epsg:4326\",\n",
    "    )\n",
    "\n",
    "\n",
    "def write_to_geoparquet(collection, cache_root, path):\n",
    "    cache_path = cache_root.joinpath(path.name).with_suffix(\".jsonl\")\n",
    "    dump_to_ndjson(collection, cache_path)\n",
    "    stac_geoparquet.arrow.parse_stac_ndjson_to_parquet(cache_path, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## connect to the STAC API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pystac_client.Client.open(\"http://localhost:9588\")\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## definition of the search\n",
    "\n",
    "The search consists of a bbox (represented by a polygon) and a timespan (represented by start / stop times)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox = shapely.box(-8, 46, 1, 51)\n",
    "datetime = [\"2022-05-10T00:00:00\", \"2022-05-12T00:00:00\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## search for satellite data\n",
    "\n",
    "This is pretty standard: provide the search criteria and the collections to search, and fetch the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "collections = [\"AVHRR_SST_METOP_B-OSISAF-L2P-v1.0\"]\n",
    "image_items = client.search(\n",
    "    collections=collections,\n",
    "    intersects=bbox,\n",
    "    datetime=datetime,\n",
    ").item_collection()\n",
    "image_items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "to be able to reuse the search results without having the STAC API available, we'll store them to [`stac-geoparquet`](https://github.com/stac-utils/stac-geoparquet) (a way of serializing STAC items to `geoparquet`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_path = cache_root.joinpath(\"avhrr-sst-metop_b.parquet\")\n",
    "write_to_geoparquet(image_items, cache_root, sst_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "reading them back allows us to visualize and inspect the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pq.read_table(sst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "lonboard.viz(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "as we can see, there's an issue with images that cross the dateline: the bounding box (as given by the dataset's attributes) spans the entire earth. To fix that, we'd have to change the way the geometry was inferred when creating the catalog."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## search for in-situ data\n",
    "\n",
    "Since the STAC catalog contains in-situ collections, we can query that in the same way (the only difference is the collection names). Additionally, we can use `stac-insitu`'s filter function to make sure trajectories actually intersect during the time we want it to intersect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_id = \"INSITU_GLO_PHYBGCWAV_DISCRETE_MYNRT_013_030\"\n",
    "short_names = [\"BO\", \"CT\", \"DB\", \"FB\", \"SM\", \"DC\", \"MO\", \"RF\", \"TS\", \"TG\", \"GL\"]\n",
    "category_names = {\n",
    "    \"bo\": \"bottles\",\n",
    "    \"ct\": \"conductivity, temperature, and depth sensors (CTD)\",\n",
    "    \"db\": \"drifting buoys\",\n",
    "    \"dc\": \"drifters\",\n",
    "    \"fb\": \"ferrybox\",\n",
    "    \"gl\": \"gliders\",\n",
    "    \"hf\": \"high frequency radars\",\n",
    "    \"ml\": \"mini loggers\",\n",
    "    \"mo\": \"moorings\",\n",
    "    \"pf\": \"profilers\",\n",
    "    \"rf\": \"river flows\",\n",
    "    \"sd\": \"saildrones\",\n",
    "    \"sm\": \"sea mammals\",\n",
    "    \"tg\": \"tide gauges\",\n",
    "    \"ts\": \"thermosalinometer\",\n",
    "    \"tx\": \"thermistor chains\",\n",
    "    \"xb\": \"expendable bathythermographs (XBT)\",\n",
    "}\n",
    "long_names = [category_names[n.lower()] for n in short_names]\n",
    "\n",
    "collections = [f\"{catalog_id}-{col}\" for col in short_names]\n",
    "collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_insitu_items = client.search(\n",
    "    collections=collections,\n",
    "    intersects=bbox,\n",
    "    datetime=datetime,\n",
    ").item_collection()\n",
    "insitu_items = filter_trajectories(all_insitu_items, bbox, datetime)\n",
    "len(insitu_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "Since `stac-geoparquet` does not support writing multiple collections into the same file at the moment, and also appears to choke on a geometry collection (i.e. items with different kinds of geometries), we have to write to `ndjson` instead: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "insitu_path = cache_root.joinpath(\n",
    "    \"insitu_global_phybgcwav_discrete_mynrt_013_030.jsonl\"\n",
    ")\n",
    "# `stac-geoparquet` currently chokes on linestring objects / multiple collections, so we have to use the `ndjson` file\n",
    "dump_to_ndjson(insitu_items, insitu_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "we can then read it back into memory and prepare for visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_table = dict(zip(collections, long_names))\n",
    "table = read_ndjson(insitu_path).assign(\n",
    "    long_names=lambda df: df[\"collection\"].map(lambda it: translation_table[it])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = table[\"collection\"].unique()\n",
    "cmap = dict(zip(categories, colormaps[\"Pastel1\"].colors))\n",
    "colors = np.stack(\n",
    "    table[\"collection\"]\n",
    "    .map(lambda it: np.asarray(cmap[it], dtype=float) * 255)\n",
    "    .to_list()\n",
    ").astype(\"uint8\")\n",
    "\n",
    "geom_types = shapely.get_type_id(table.geometry).to_numpy()\n",
    "\n",
    "scatterplot_colors = colors[geom_types == shapely.GeometryType.POINT, :]\n",
    "path_colors = colors[geom_types == shapely.GeometryType.LINESTRING, :]\n",
    "\n",
    "kwargs = {\n",
    "    \"scatterplot_kwargs\": {\"get_fill_color\": scatterplot_colors},\n",
    "    \"path_kwargs\": {\"get_color\": path_colors},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "lonboard.viz(table, **kwargs)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
