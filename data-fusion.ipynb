{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "import foscat.Synthesis as synthe\n",
    "import foscat.xarray as foscat\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from rich.console import Console\n",
    "from rich.progress import track\n",
    "\n",
    "console = Console()\n",
    "xr.set_options(display_expand_attrs=False, display_expand_data=False, keep_attrs=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = foscat.Parameters(\n",
    "    n_orientations=4, kernel_size=3, jmax_delta=0, dtype=\"float32\", backend=\"torch\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = pathlib.Path(\"data/healpix\")\n",
    "stats_root = pathlib.Path(\"data/stats\")\n",
    "stats_root.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## compute stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = sorted(data_root.glob(\"*/*.zarr\"))[:4]\n",
    "data_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_key(ds, options):\n",
    "    standard_names = ds.cf.standard_names\n",
    "    for option in options:\n",
    "        standard_name = standard_names.get(option)\n",
    "        if standard_name is not None:\n",
    "            return standard_name[0]\n",
    "\n",
    "    raise ValueError(f\"could not find a variable using the standard names {options}\")\n",
    "\n",
    "\n",
    "arrs = []\n",
    "for path in track(data_files):\n",
    "    ds = xr.open_dataset(path, chunks=None, decode_timedelta=True).load().dggs.decode()\n",
    "    key = detect_key(ds, [\"sea_water_temperature\", \"sea_surface_subskin_temperature\"])\n",
    "    temperature = ds[key].where(lambda arr: arr.notnull(), drop=True)\n",
    "    temperature.encoding[\"source\"] = path\n",
    "\n",
    "    if \"DEPTH\" in temperature.dims:\n",
    "        temperature = temperature.isel(DEPTH=0)\n",
    "\n",
    "    arrs.append(temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_arrs_ = xr.align(\n",
    "    *[arr.drop_indexes(\"cell_ids\").set_xindex(\"cell_ids\").squeeze() for arr in arrs],\n",
    "    join=\"outer\",\n",
    ")\n",
    "aligned_arrs = [x.dggs.decode() for x in aligned_arrs_]\n",
    "aligned_arrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_ = []\n",
    "for arr in track(aligned_arrs):\n",
    "    console.log(f\"computing stats for {path.stem}\")\n",
    "    arr_ = arr.where(arr.notnull(), drop=True)\n",
    "    stats = foscat.reference_statistics(\n",
    "        arr_ - arr_.median(), parameters=params, variances=True, jmax=5, norm=\"self\"\n",
    "    )\n",
    "\n",
    "    stats_.append(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def The_loss(u, scat_operator, args):\n",
    "    ref = args[0]\n",
    "    sref = args[1]\n",
    "    cell_ids = args[2]\n",
    "    nside = args[3]\n",
    "\n",
    "    # compute scattering covariance of the current synthetised map called u\n",
    "    learn = scat_operator.eval(u, norm=\"self\", cell_ids=cell_ids, nside=nside, Jmax=5)\n",
    "\n",
    "    # make the difference withe the reference coordinates\n",
    "    loss = scat_operator.reduce_distance(learn, ref, sigma=sref)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "scat = params.cache\n",
    "loss_functions = []\n",
    "for arr, stats in zip(aligned_arrs, stats_):\n",
    "    ref, sref = foscat.statistics._xarray_to_scat_cov(stats)\n",
    "\n",
    "    nside = arr.dggs.grid_info.nside\n",
    "\n",
    "    loss_functions.append(\n",
    "        synthe.Loss(The_loss, scat, ref, sref, arr.dggs.coord.data, nside)\n",
    "    )\n",
    "\n",
    "sy = synthe.Synthesis(loss_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cell_ids = arrs[0].sizes[\"cells\"]\n",
    "std = np.max([arr.std().item() for arr in aligned_arrs])\n",
    "imap = np.random.randn(1, n_cell_ids) * std\n",
    "\n",
    "omap = scat.to_numpy(sy.run(imap, EVAL_FREQUENCY=1, NUM_EPOCHS=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthesized = xr.DataArray(\n",
    "    np.squeeze(omap), dims=\"cells\", coords={\"cell_ids\": aligned_arrs[0].dggs.coord}\n",
    ").dggs.decode(arrs[0].dggs.grid_info)\n",
    "synthesized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthesized.dggs.explore()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
